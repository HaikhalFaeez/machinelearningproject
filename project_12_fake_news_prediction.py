# -*- coding: utf-8 -*-
"""Project 12 - Fake News Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cmLutuL06knnFwK58fFDWQJlqIZHfI1A

1. To identify whether the news is a fake news or real news - Binary Classification Problem
2. ML Model - Logistic Regression Model (Supervised ML)
3. Work Flow

  * Collect News Data - Kaggle Dataset
  * Data Pre-Processing
  * Train-Test Split
  * Machine Learning Training - Logistic Regression Model (Supervised ML)
  * Develop Prediction System - Feed new news data to the trained model to predict the news type

About the Dataset:

1. id: unique id for a news article

2. title: the title of a news article

3. author: author of the news article

4. text: the text of the article, could be incomplete

5. label: a label that marks whether the news article is fake or real

1 --> Fake News

0 --> Real News

Import the Dependencies
"""

import numpy as np
import pandas as pd
import re # regular expression - useful to search text in a document
import nltk #natural language toolkit
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

nltk.download('stopwords')

print(stopwords.words('english'))

"""Data Collection & Pre-Processing"""

news_data = pd.read_csv('/content/fake_news_dataset.csv')

news_data.head()

news_data.tail()

news_data.shape

news_data.isnull().sum()

#replacing the null values with empty string

news_data = news_data.fillna('')

news_data.isnull().sum()

# merging the author name and news title columns - to reduce processing time since text data is large

news_data['content'] = news_data['author'] + ' ' + news_data['title']

X = news_data.drop(columns='label', axis=1)
Y = news_data['label']

print(X)

print(Y)

"""Stemming

* Stemming is a process of reducing a word to its Root word

* example: actor, actress, acting --> act
"""

port_stem = PorterStemmer()

def stemming(content):
    stemmed_content = re.sub('[^a-zA-Z]',' ', content) #excluding the punctuation, exclamation, question marks, full stop, comma, etc...
    stemmed_content = stemmed_content.lower() # convert uppercase letter to lowercase letter
    stemmed_content = stemmed_content.split() # split & convert the text to a list
    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')] #changing all the words beside stopwords to its root words
    stemmed_content = ' '.join(stemmed_content)
    return stemmed_content

news_data['content'] = news_data['content'].apply(stemming)

print(news_data['content'])

X = news_data['content'].values
Y = news_data['label'].values

print(X)

print(Y)

Y.shape

"""TfidfVectorizer

* Convert Textual Data to Feature Vectors (Numerical Data)
"""

vectorizer = TfidfVectorizer()
vectorizer.fit(X)

X = vectorizer.transform(X)

print(X)

"""Train-Test Split"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)

"""Machine Learning Training - Logistic Regression Model"""

model = LogisticRegression()

model.fit(X_train, Y_train)

"""Model Evaluation"""

# accuracy on training data

X_train_prediction = model.predict(X_train)
train_data_accuracy = accuracy_score(X_train_prediction, Y_train)
print('The training data accuracy = ', train_data_accuracy)

# accuracy on test data

X_test_prediction = model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction, Y_test)
print('The test data accuracy = ', test_data_accuracy)

"""Predictive System"""

input_data = (X_test[0])

prediction = model.predict(input_data)
print(prediction)

if (prediction[0] == 0):
  print('The news is Real')

else:
  print('The news is Fake')

print(Y_test[0])